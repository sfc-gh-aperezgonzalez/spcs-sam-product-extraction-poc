{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SAM Batch Product Extraction\n",
        "\n",
        "Process multiple ad images through SAM inference service.\n",
        "\n",
        "**What this does:**\n",
        "1. Lists ad images from `AD_INPUT_STAGE/ads/`\n",
        "2. Processes N images (controlled by `LIMIT`)\n",
        "3. Calls SAM service function for each image\n",
        "4. Outputs product crops to `AD_OUTPUT_STAGE/{run_id}/`\n",
        "\n",
        "**Prerequisites:**\n",
        "- Upload this notebook to Snowflake (Snowsight → Projects → Notebooks)\n",
        "- Select warehouse: `SAM_DEMO_WH`\n",
        "- Database/Schema: `SHALION_HF_DEMO.PRODUCT_EXTRACTION`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Import Libraries and Get Snowpark Session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "\n",
        "# Get the active Snowpark session\n",
        "session = get_active_session()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration: Batch Size and Run ID\n",
        "\n",
        "Set how many images to process and generate a unique run ID for organizing output files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Control how many images to process\n",
        "LIMIT = 5\n",
        "\n",
        "# Unique run ID for output organization\n",
        "run_id = datetime.now().strftime(\"run_%Y%m%d_%H%M%S\")\n",
        "\n",
        "print(f\"Run ID: {run_id}\")\n",
        "print(f\"Processing limit: {LIMIT} images\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: List Available Ad Images\n",
        "\n",
        "Query the input stage directory to find all JPEG/PNG images in the `ads/` folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images_df = session.sql(\"\"\"\n",
        "    SELECT \n",
        "        RELATIVE_PATH AS image_path,\n",
        "        SIZE AS file_size_bytes,\n",
        "        LAST_MODIFIED\n",
        "    FROM DIRECTORY(@SHALION_HF_DEMO.PRODUCT_EXTRACTION.AD_INPUT_STAGE)\n",
        "    WHERE RELATIVE_PATH LIKE 'ads/%'\n",
        "      AND (RELATIVE_PATH LIKE '%.jpg' OR RELATIVE_PATH LIKE '%.jpeg' OR RELATIVE_PATH LIKE '%.png')\n",
        "    ORDER BY LAST_MODIFIED DESC\n",
        "\"\"\").limit(LIMIT)\n",
        "\n",
        "images_df.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Process Images Through SAM Inference\n",
        "\n",
        "Call `EXTRACT_PRODUCTS()` function which runs SAM on GPU to extract product regions from each image. Handles errors gracefully and continues processing if individual images fail.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = []\n",
        "errors = []\n",
        "\n",
        "for row in images_df.collect():\n",
        "    image_path = row['IMAGE_PATH']\n",
        "    print(f\"\\nProcessing: {image_path}\")\n",
        "    \n",
        "    try:\n",
        "        # Call SAM inference service\n",
        "        result_str = session.sql(f\"\"\"\n",
        "            SELECT SHALION_HF_DEMO.PRODUCT_EXTRACTION.EXTRACT_PRODUCTS(\n",
        "                '@SHALION_HF_DEMO.PRODUCT_EXTRACTION.AD_INPUT_STAGE/{image_path}',\n",
        "                '{run_id}/{image_path.split(\"/\")[-1].split(\".\")[0]}/'\n",
        "            )\n",
        "        \"\"\").collect()[0][0]\n",
        "        \n",
        "        result = json.loads(result_str)\n",
        "        results.append({\n",
        "            'image': image_path,\n",
        "            'num_products': result['num_products'],\n",
        "            'product_likely': result['product_likely'],\n",
        "            'crops': result['crops']\n",
        "        })\n",
        "        \n",
        "        print(f\"  ✓ Found {result['num_products']} products\")\n",
        "        print(f\"  ✓ Product likely: {result['product_likely']}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        error_msg = str(e)\n",
        "        errors.append({'image': image_path, 'error': error_msg})\n",
        "        print(f\"  ✗ Failed: {error_msg[:100]}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Batch complete: {len(results)} images processed successfully\")\n",
        "if errors:\n",
        "    print(f\"Failed: {len(errors)} images (see errors list)\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Display Results Summary\n",
        "\n",
        "Show detailed results including successful extractions with crop URLs and any errors encountered.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nResults Summary:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"✓ Successful: {len(results)} images\")\n",
        "print(f\"✗ Failed: {len(errors)} images\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if results:\n",
        "    print(\"\\nSuccessful Extractions:\")\n",
        "    for r in results:\n",
        "        print(f\"{r['image']:40s} → {r['num_products']} products\")\n",
        "        for crop in r['crops']:\n",
        "            print(f\"  - {crop}\")\n",
        "    print(f\"\\nTotal crops generated: {sum(r['num_products'] for r in results)}\")\n",
        "\n",
        "if errors:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Failed Images:\")\n",
        "    for e in errors:\n",
        "        print(f\"✗ {e['image']}\")\n",
        "        print(f\"  Error: {e['error'][:150]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download Output Images\n",
        "\n",
        "Replace `{run_id}` with the actual run ID from the config cell above.\n",
        "\n",
        "```bash\n",
        "snow stage copy @SHALION_HF_DEMO.PRODUCT_EXTRACTION.AD_OUTPUT_STAGE/{run_id}/ ./output/{run_id}/ \\\n",
        "  --recursive \\\n",
        "  --database SHALION_HF_DEMO \\\n",
        "  --schema PRODUCT_EXTRACTION\n",
        "```\n",
        "\n",
        "**Example:**\n",
        "```bash\n",
        "# If run_id = run_20251118_025350\n",
        "snow stage copy @SHALION_HF_DEMO.PRODUCT_EXTRACTION.AD_OUTPUT_STAGE/run_20251118_025350/ ./output/run_20251118_025350/ \\\n",
        "  --recursive \\\n",
        "  --database SHALION_HF_DEMO \\\n",
        "  --schema PRODUCT_EXTRACTION\n",
        "```\n",
        "\n",
        "Command will download all PNG product crops to your local `./output/{run_id}/` directory.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
